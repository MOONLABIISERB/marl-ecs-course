# Assignment 1 and Assignment 2 Results
## Output and Results have been sent as jpg file in respective folders
## Q1 Result:
#### Optimum Values
value(Hostel)= 16.05623156 

value(academic building)= 21.84650722 

value(canteen)= 18.82669839

#### Optimum policy

π(Hostel)= Study

π(academic building)= Study

π(canteen)= Study

## Q2 Result:

Value Iteration and Policy iteration values have been uploaded along with code and quiver plot

# MultiAgent-Rl_Assignment2
## Q1
### Value Iteration result
#### Value iteration converts and output shows optimum policy along with optimum values.

## Q2
#### a) Value Iteration Result: The grid is the same structure as the one provided in the assignment pdf. Value iteration result shows that the terminal state is reached after 10 iteration. The state is taken as a tuple of the human and the box state. The optimum policy and optimum state values of the state has been given in the output. 

#### b) Monte Carlo result: After performing 100000 episodes Monte Carlo fails to find optimum policy, and the block state loops at the terminal state edge (4,4).

### Difference between Value Iteration and Monte Carlo:
#### Value iteration converges quicker than Monte Carlo since the latter has an exploring nature, i.e exploring starts.
