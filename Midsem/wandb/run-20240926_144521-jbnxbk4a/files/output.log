Episode 0, Avg Loss: 1000.0000, Reward: -29.962269115448002, exploration: 1.0000
Episode 100, Avg Loss: 1000.0000, Reward: -84.9296220703125, exploration: 0.9517
Episode 200, Avg Loss: 1000.0000, Reward: -126.45628124999999, exploration: 0.9058
Episode 300, Avg Loss: 1000.0000, Reward: -188.95146484375002, exploration: 0.8621
Episode 400, Avg Loss: 1000.0000, Reward: -241.51169921874998, exploration: 0.8205
Episode 500, Avg Loss: 1000.0000, Reward: -292.82282421875, exploration: 0.7810
Episode 600, Avg Loss: 1000.0000, Reward: -308.8920703125, exploration: 0.7434
Episode 700, Avg Loss: 1000.0000, Reward: -268.43666015625, exploration: 0.7076
Episode 800, Avg Loss: 1000.0000, Reward: -394.95185156249994, exploration: 0.6736
Episode 900, Avg Loss: 1000.0000, Reward: -380.71201562500005, exploration: 0.6413
Episode 1000, Avg Loss: 663.1510, Reward: -415.97162499999996, exploration: 0.6105
Episode 1100, Avg Loss: 141.7307, Reward: -380.47096875, exploration: 0.5812
Episode 1200, Avg Loss: 185.8430, Reward: -406.6582734375, exploration: 0.5533
Episode 1300, Avg Loss: 191.2274, Reward: -599.833625, exploration: 0.5268
Episode 1400, Avg Loss: 209.0903, Reward: -458.6810234375, exploration: 0.5016
Episode 1500, Avg Loss: 228.8364, Reward: -387.8897265625, exploration: 0.4776
Episode 1600, Avg Loss: 250.1803, Reward: -711.7628203125, exploration: 0.4548
Episode 1700, Avg Loss: 260.0932, Reward: -638.6627343749999, exploration: 0.4331
Episode 1800, Avg Loss: 286.6087, Reward: -552.8736796875, exploration: 0.4125
Episode 1900, Avg Loss: 299.1675, Reward: -693.5139765625, exploration: 0.3929
Traceback (most recent call last):
  File "/home/protomate/marl-ecs-course/Midsem/modified_tsp.py", line 77, in <module>
    main()
  File "/home/protomate/marl-ecs-course/Midsem/modified_tsp.py", line 52, in main
    loss = agent.learn_from_memory(batch_size=batchSize)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/protomate/marl-ecs-course/Midsem/agent.py", line 75, in learn_from_memory
    transitions = self.memory.sample(batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/protomate/marl-ecs-course/Midsem/agent.py", line 24, in sample
    return random.sample(self.memory, batch_size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/protomate/.pyenv/versions/3.12.4/lib/python3.12/random.py", line 451, in sample
    result[i] = population[j]
    ~~~~~~^^^
KeyboardInterrupt
