Episode 0,  Reward: 203.08, Profit: 236.54, Distance: 50.13 Loss: 1000.00
Episode 100,  Reward: 244.82, Profit: 242.80, Distance: 52.30 Loss: 5.45
Traceback (most recent call last):
  File "/Users/agam/projects/marl-ecs-course/Midsem/modified_tsp.py", line 130, in <module>
    main()
  File "/Users/agam/projects/marl-ecs-course/Midsem/modified_tsp.py", line 70, in main
    loss = agent.learn_from_memory(batch_size=batchSize)
  File "/Users/agam/projects/marl-ecs-course/Midsem/agent.py", line 127, in learn_from_memory
    self.optimizer.step()
  File "/Users/agam/miniconda3/envs/marl/lib/python3.10/site-packages/torch/optim/optimizer.py", line 484, in wrapper
    out = func(*args, **kwargs)
  File "/Users/agam/miniconda3/envs/marl/lib/python3.10/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/Users/agam/miniconda3/envs/marl/lib/python3.10/site-packages/torch/optim/adam.py", line 226, in step
    adam(
  File "/Users/agam/miniconda3/envs/marl/lib/python3.10/site-packages/torch/optim/optimizer.py", line 161, in maybe_fallback
    return func(*args, **kwargs)
  File "/Users/agam/miniconda3/envs/marl/lib/python3.10/site-packages/torch/optim/adam.py", line 766, in adam
    func(
  File "/Users/agam/miniconda3/envs/marl/lib/python3.10/site-packages/torch/optim/adam.py", line 433, in _single_tensor_adam
    param.addcdiv_(exp_avg, denom, value=-step_size)
KeyboardInterrupt
