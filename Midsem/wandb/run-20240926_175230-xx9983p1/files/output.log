Episode 0, Avg Loss: 1000.0000, Reward: -29958.36820411682, exploration: 0.7000
Episode 100, Avg Loss: 3387.9281, Reward: -75795.66455078125, exploration: 0.6663
Episode 200, Avg Loss: 7179.0760, Reward: -123348.1943359375, exploration: 0.6343
Episode 300, Avg Loss: 12841.4670, Reward: -161835.71875, exploration: 0.6039
Episode 400, Avg Loss: 20334.2217, Reward: -197770.818359375, exploration: 0.5749
Episode 500, Avg Loss: 32991.2846, Reward: -232990.048828125, exploration: 0.5474
Episode 600, Avg Loss: 36173.9768, Reward: -241216.5859375, exploration: 0.5212
Episode 700, Avg Loss: 44869.1533, Reward: -269345.9921875, exploration: 0.4962
Episode 800, Avg Loss: 48163.5352, Reward: -296832.671875, exploration: 0.4725
Episode 900, Avg Loss: 66890.1078, Reward: -368213.20703125, exploration: 0.4500
Episode 1000, Avg Loss: 74812.1656, Reward: -299508.11328125, exploration: 0.4285
Episode 1100, Avg Loss: 68714.8902, Reward: -374841.14453125, exploration: 0.4081
Episode 1200, Avg Loss: 84275.7719, Reward: -340064.984375, exploration: 0.3887
Episode 1300, Avg Loss: 84412.8965, Reward: -488626.4453125, exploration: 0.3702
Episode 1400, Avg Loss: 108513.7930, Reward: -377160.0625, exploration: 0.3526
Episode 1500, Avg Loss: 106879.1406, Reward: -247206.4296875, exploration: 0.3359
Episode 1600, Avg Loss: 108225.0492, Reward: -488936.359375, exploration: 0.3200
Episode 1700, Avg Loss: 123047.0023, Reward: -346072.34375, exploration: 0.3049
Traceback (most recent call last):
  File "/home/protomate/marl-ecs-course/Midsem/modified_tsp.py", line 79, in <module>
    main()
  File "/home/protomate/marl-ecs-course/Midsem/modified_tsp.py", line 52, in main
    loss = agent.learn_from_memory(batch_size=batchSize)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/protomate/marl-ecs-course/Midsem/agent.py", line 108, in learn_from_memory
    self.optimizer.step()
  File "/home/protomate/.pyenv/versions/3.12.4/lib/python3.12/site-packages/torch/optim/optimizer.py", line 484, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/protomate/.pyenv/versions/3.12.4/lib/python3.12/site-packages/torch/optim/optimizer.py", line 89, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/protomate/.pyenv/versions/3.12.4/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    adam(
  File "/home/protomate/.pyenv/versions/3.12.4/lib/python3.12/site-packages/torch/optim/optimizer.py", line 161, in maybe_fallback
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/protomate/.pyenv/versions/3.12.4/lib/python3.12/site-packages/torch/optim/adam.py", line 766, in adam
    func(
  File "/home/protomate/.pyenv/versions/3.12.4/lib/python3.12/site-packages/torch/optim/adam.py", line 585, in _multi_tensor_adam
    1 - beta1 ** _get_value(step) for step in device_state_steps
                 ^^^^^^^^^^^^^^^^
  File "/home/protomate/.pyenv/versions/3.12.4/lib/python3.12/site-packages/torch/optim/optimizer.py", line 104, in _get_value
    return x.item() if isinstance(x, torch.Tensor) else x
           ^^^^^^^^
KeyboardInterrupt
