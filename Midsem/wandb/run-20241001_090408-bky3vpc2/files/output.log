Episode 0,  Reward: 62.60, Profit: 47.13, Distance: 78.12 Loss: 1000.00 Initial Profits: [ 20.  60.  80.  50.  30.  90.  10.  40. 100.  70.]
Episode 100,  Reward: 56.18, Profit: 99.55, Distance: 73.38 Loss: 0.25 Initial Profits: [ 80.  20.  30.  10.  40.  50.  60.  90.  70. 100.]
Episode 200,  Reward: 178.67, Profit: 212.79, Distance: 64.89 Loss: 1.34 Initial Profits: [ 80.  20.  30.  10.  40.  50.  60.  90.  70. 100.]
Episode 300,  Reward: 205.93, Profit: 255.05, Distance: 54.01 Loss: 2.69 Initial Profits: [ 80.  20.  30.  10.  40.  50.  60.  90.  70. 100.]
Episode 400,  Reward: 29.69, Profit: 77.61, Distance: 86.90 Loss: 3.60 Initial Profits: [ 80.  20.  30.  10.  40.  50.  60.  90.  70. 100.]
Episode 500,  Reward: 274.98, Profit: 312.87, Distance: 44.30 Loss: 3.10 Initial Profits: [ 80.  20.  30.  10.  40.  50.  60.  90.  70. 100.]
Episode 600,  Reward: 214.41, Profit: 241.43, Distance: 57.02 Loss: 2.16 Initial Profits: [ 80.  20.  30.  10.  40.  50.  60.  90.  70. 100.]
Traceback (most recent call last):
  File "/Users/agam/projects/marl-ecs-course/Midsem/modified_tsp.py", line 131, in <module>
    main()
  File "/Users/agam/projects/marl-ecs-course/Midsem/modified_tsp.py", line 70, in main
    loss = agent.learn_from_memory(batch_size=batchSize)
  File "/Users/agam/projects/marl-ecs-course/Midsem/agent.py", line 125, in learn_from_memory
    loss.backward()
  File "/Users/agam/miniconda3/envs/marl/lib/python3.10/site-packages/torch/_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "/Users/agam/miniconda3/envs/marl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 289, in backward
    _engine_run_backward(
  File "/Users/agam/miniconda3/envs/marl/lib/python3.10/site-packages/torch/autograd/graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
