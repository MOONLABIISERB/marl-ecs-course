{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CUhWNzT_rZz4"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = ['Hostel', 'Academic Building', 'Canteen']\n",
        "\n",
        "actions = ['Attends Classes', 'Hungry']\n",
        "\n",
        "rewards = {\n",
        "    'Hostel': -1,\n",
        "    'Academic Building': +3,\n",
        "    'Canteen': +1\n",
        "}\n",
        "\n",
        "transition_probabilities = {\n",
        "    'Hostel': {\n",
        "        'Attends Classes': {'Academic Building': 0.5, 'Hostel': 0.5},\n",
        "        'Hungry': {'Canteen': 1.0}\n",
        "    },\n",
        "    'Academic Building': {\n",
        "        'Attends Classes': {'Academic Building': 0.7, 'Canteen': 0.3},\n",
        "        'Hungry': {'Canteen': 0.8, 'Academic Building': 0.2}\n",
        "    },\n",
        "    'Canteen': {\n",
        "        'Attends Classes': {'Academic Building': 0.6, 'Hostel': 0.3, 'Canteen': 0.1},\n",
        "        'Hungry': {'Canteen': 1.0}\n",
        "    }\n",
        "}\n",
        "\n",
        "gamma = 0.9"
      ],
      "metadata": {
        "id": "4jgHGo-Prb7F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def value_iteration(states, actions, rewards, transition_probabilities, gamma=0.9, theta=1e-6):\n",
        "    #Initialize value function\n",
        "    V = {s: 0 for s in states}\n",
        "\n",
        "    while True:\n",
        "        delta = 0\n",
        "\n",
        "        for s in states:\n",
        "            v = V[s]\n",
        "\n",
        "            V[s] = max(sum(transition_probabilities[s][a][s_prime] *\n",
        "                           (rewards[s_prime] + gamma * V[s_prime])\n",
        "                           for s_prime in transition_probabilities[s][a])\n",
        "                       for a in actions)\n",
        "\n",
        "            delta = max(delta, abs(v - V[s]))\n",
        "\n",
        "\n",
        "        if delta < theta:\n",
        "            break\n",
        "\n",
        "    #Determine the optimal policy\n",
        "    policy = {}\n",
        "    for s in states:\n",
        "        best_action = None\n",
        "        best_value = float('-inf')\n",
        "\n",
        "        for a in actions:\n",
        "            action_value = sum(transition_probabilities[s][a][s_prime] *\n",
        "                               (rewards[s_prime] + gamma * V[s_prime])\n",
        "                               for s_prime in transition_probabilities[s][a])\n",
        "            if action_value > best_value:\n",
        "                best_value = action_value\n",
        "                best_action = a\n",
        "\n",
        "        policy[s] = best_action\n",
        "\n",
        "    return V, policy\n",
        "\n",
        "V, policy = value_iteration(states, actions, rewards, transition_probabilities, gamma)"
      ],
      "metadata": {
        "id": "o1aWts5gsv1g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Optimal Value Functions are :\")\n",
        "for s in V:\n",
        "    print(f\"V of {s} = {V[s]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilg5QUw1tqBA",
        "outputId": "ec0ff775-a207-4adb-95a6-750901c3bd38"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Optimal Value Functions are :\n",
            "V of Hostel = 18.95\n",
            "V of Academic Building = 20.94\n",
            "V of Canteen = 19.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Optimal Policy are:\")\n",
        "for s in policy:\n",
        "    print(f\"π of {s} = {policy[s]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Muo5FF3Ut38G",
        "outputId": "275466b5-47b9-44f2-d928-741b1320deb6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Optimal Policy are:\n",
            "π of Hostel = Attends Classes\n",
            "π of Academic Building = Attends Classes\n",
            "π of Canteen = Attends Classes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_evaluation(policy, states, actions, rewards, transition_probabilities, gamma=0.9, theta=1e-6):\n",
        "    # Start with a zero value function for all states\n",
        "    V = {s: 0 for s in states}\n",
        "\n",
        "    while True:\n",
        "        max_change = 0\n",
        "        # Iterate through each state\n",
        "        for s in states:\n",
        "            previous_value = V[s]\n",
        "            chosen_action = policy[s]\n",
        "\n",
        "            V[s] = sum(\n",
        "                transition_probabilities[s][chosen_action].get(s_prime, 0) *\n",
        "                (rewards.get(s_prime, 0) + gamma * V[s_prime])\n",
        "                for s_prime in transition_probabilities[s][chosen_action]\n",
        "            )\n",
        "\n",
        "            max_change = max(max_change, abs(previous_value - V[s]))\n",
        "\n",
        "        if max_change < theta:\n",
        "            break\n",
        "\n",
        "    return V\n"
      ],
      "metadata": {
        "id": "W2SPd0fYuo6j"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_iteration(states, actions, rewards, transition_probabilities, gamma=0.9):\n",
        "    # Initialize a random policy\n",
        "    policy = {s: np.random.choice(actions) for s in states}\n",
        "\n",
        "    while True:\n",
        "        # Policy Evaluation\n",
        "        V = policy_evaluation(policy, states, actions, rewards, transition_probabilities, gamma)\n",
        "\n",
        "        policy_stable = True\n",
        "\n",
        "        # Policy Improvement\n",
        "        for s in states:\n",
        "            old_action = policy[s]\n",
        "\n",
        "            best_action = None\n",
        "            best_value = float('-inf')\n",
        "\n",
        "            for a in actions:\n",
        "                action_value = sum(transition_probabilities[s][a][s_prime] *\n",
        "                                   (rewards[s_prime] + gamma * V[s_prime])\n",
        "                                   for s_prime in transition_probabilities[s][a])\n",
        "                if action_value > best_value:\n",
        "                    best_value = action_value\n",
        "                    best_action = a\n",
        "\n",
        "            policy[s] = best_action\n",
        "\n",
        "            if old_action != best_action:\n",
        "                policy_stable = True\n",
        "\n",
        "        if policy_stable:\n",
        "            break\n",
        "\n",
        "    return V, policy\n",
        "\n",
        "V_policy, policy = policy_iteration(states, actions, rewards, transition_probabilities, gamma)"
      ],
      "metadata": {
        "id": "-m876nKTvXGq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Optimal Value Function (Policy Iteration):\")\n",
        "for s in V_policy:\n",
        "    print(f\"V of {s} = {V_policy[s]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEYjU96Qvd5W",
        "outputId": "732a481c-ee74-4923-e9d8-760309a10ace"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Optimal Value Function (Policy Iteration):\n",
            "V of Hostel = 13.10\n",
            "V of Academic Building = 13.78\n",
            "V of Canteen = 10.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Optimal Policy (Policy Iteration):\")\n",
        "for s in policy:\n",
        "    print(f\"π of {s} = {policy[s]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbDZ413xwBtw",
        "outputId": "bc243672-d0a0-4e1d-85ae-6fb21df5711e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Optimal Policy (Policy Iteration):\n",
            "π of Hostel = Attends Classes\n",
            "π of Academic Building = Attends Classes\n",
            "π of Canteen = Attends Classes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fRqnI14TwKmJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}