{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import random"
      ],
      "metadata": {
        "id": "2Q4_w-W9yma2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment Setup\n",
        "# 0: empty, 1: wall, 2: box, 3: storage, 4: agent\n",
        "grid = np.array([\n",
        "    [1, 1, 1, 1, 1, 1],\n",
        "    [1, 0, 4, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 1, 1],\n",
        "    [1, 3, 0, 0, 0, 1],\n",
        "    [1, 0, 0, 2, 0, 1],\n",
        "    [1, 0, 0, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1, 1],\n",
        "])\n",
        "\n",
        "# State is a tuple: (agent_position, box_positions)\n",
        "initial_agent_pos = (1, 2)\n",
        "initial_box_pos = [(4, 3)]\n",
        "storage_pos = [(3, 1)]\n",
        "\n",
        "# Constants\n",
        "GRID_ROWS = 7\n",
        "GRID_COLS = 6\n",
        "ACTIONS = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
        "DISCOUNT_FACTOR = 0.9\n",
        "THRESHOLD = 1e-4\n",
        "EPISODES = 1000\n",
        "\n",
        "# Movement directions for each action\n",
        "action_to_delta = {\n",
        "    'UP': (-1, 0),\n",
        "    'DOWN': (1, 0),\n",
        "    'LEFT': (0, -1),\n",
        "    'RIGHT': (0, 1)\n",
        "}"
      ],
      "metadata": {
        "id": "xy2l-qEJym62"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Q-value table and returns\n",
        "Q = defaultdict(lambda: {action: 0.0 for action in ACTIONS})\n",
        "returns = defaultdict(lambda: {action: [] for action in ACTIONS})\n",
        "\n",
        "def generate_episode(grid, agent_pos, box_pos, storage_pos):\n",
        "    episode = []\n",
        "    state = (agent_pos, tuple(box_pos))\n",
        "    while not is_terminal(state, storage_pos):\n",
        "        action = random.choice(ACTIONS)\n",
        "        next_state, reward = step(state, action, grid, storage_pos)\n",
        "        episode.append((state, action, reward))\n",
        "        state = next_state\n",
        "    return episode"
      ],
      "metadata": {
        "id": "bMyq53hGym9m"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Monte Carlo First-Vist"
      ],
      "metadata": {
        "id": "Ez3Z04WrzLsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def first_visit_mc(grid, agent_pos, box_pos, storage_pos):\n",
        "    for _ in range(EPISODES):\n",
        "        episode = generate_episode(grid, agent_pos, box_pos, storage_pos)\n",
        "        visited_state_action_pairs = set()\n",
        "        G = 0\n",
        "\n",
        "        for state, action, reward in reversed(episode):\n",
        "            G = reward + DISCOUNT * G\n",
        "            if (state, action) not in visited_state_action_pairs:\n",
        "                visited_state_action_pairs.add((state, action))\n",
        "                returns[state][action].append(G)\n",
        "                Q[state][action] = np.mean(returns[state][action])\n",
        "\n",
        "def step(state, action, grid, storage_pos):\n",
        "    agent_pos, box_positions = state\n",
        "    delta = action_to_delta[action]\n",
        "\n",
        "    # Calculate new position for the agent\n",
        "    new_agent_pos = (agent_pos[0] + delta[0], agent_pos[1] + delta[1])\n",
        "\n",
        "    # Check if new position is valid (i.e., not a wall or out of bounds)\n",
        "    if grid[new_agent_pos[0], new_agent_pos[1]] == 1:\n",
        "        return state, -1  # Invalid move (into a wall)\n",
        "\n",
        "    # Check if new position has a box\n",
        "    new_box_positions = list(box_positions)\n",
        "    if new_agent_pos in box_positions:\n",
        "        # Calculate new position for the box\n",
        "        new_box_pos = (new_agent_pos[0] + delta[0], new_agent_pos[1] + delta[1])\n",
        "\n",
        "        # Check if the box can move (i.e., not blocked by wall or another box)\n",
        "        if grid[new_box_pos[0], new_box_pos[1]] == 1 or new_box_pos in box_positions:\n",
        "            return state, -1  # Invalid move (box cannot move)\n",
        "        else:\n",
        "            # Move the box\n",
        "            new_box_positions[box_positions.index(new_agent_pos)] = new_box_pos\n",
        "\n",
        "    # Return new state and reward\n",
        "    if all(box in storage_pos for box in new_box_positions):\n",
        "        return (new_agent_pos, tuple(new_box_positions)), 1  # All boxes in storage: terminal state\n",
        "    else:\n",
        "        return (new_agent_pos, tuple(new_box_positions)), 0  # Valid move, continue\n",
        "\n",
        "def is_terminal(state, storage_pos):\n",
        "    _, box_positions = state\n",
        "    return all(box in storage_pos for box in box_positions)\n",
        "\n",
        "# Call First-Visit Monte Carlo Control\n",
        "first_visit_mc(grid, initial_agent_pos, initial_box_pos, storage_pos)"
      ],
      "metadata": {
        "id": "0m9SL-j-ynAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Monte Carlo Every-Visit"
      ],
      "metadata": {
        "id": "qpsT-Amxzy18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def every_visit_mc(grid, agent_pos, box_pos, storage_pos):\n",
        "    for _ in range(EPISODES):\n",
        "        episode = generate_episode(grid, agent_pos, box_pos, storage_pos)\n",
        "        G = 0\n",
        "\n",
        "        for state, action, reward in reversed(episode):\n",
        "            G = reward + DISCOUNT * G\n",
        "            returns[state][action].append(G)\n",
        "            Q[state][action] = np.mean(returns[state][action])\n",
        "\n",
        "def step(state, action, grid, storage_pos):\n",
        "    agent_pos, box_positions = state\n",
        "    delta = action_to_delta[action]\n",
        "\n",
        "    # Calculate new position for the agent\n",
        "    new_agent_pos = (agent_pos[0] + delta[0], agent_pos[1] + delta[1])\n",
        "\n",
        "    # Check if new position is valid (i.e., not a wall or out of bounds)\n",
        "    if grid[new_agent_pos[0], new_agent_pos[1]] == 1:\n",
        "        return state, -1  # Invalid move (into a wall)\n",
        "\n",
        "    # Check if new position has a box\n",
        "    new_box_positions = list(box_positions)\n",
        "    if new_agent_pos in box_positions:\n",
        "        # Calculate new position for the box\n",
        "        new_box_pos = (new_agent_pos[0] + delta[0], new_agent_pos[1] + delta[1])\n",
        "\n",
        "        # Check if the box can move (i.e., not blocked by wall or another box)\n",
        "        if grid[new_box_pos[0], new_box_pos[1]] == 1 or new_box_pos in box_positions:\n",
        "            return state, -1  # Invalid move (box cannot move)\n",
        "        else:\n",
        "            # Move the box\n",
        "            new_box_positions[box_positions.index(new_agent_pos)] = new_box_pos\n",
        "\n",
        "    # Return new state and reward\n",
        "    if all(box in storage_pos for box in new_box_positions):\n",
        "        return (new_agent_pos, tuple(new_box_positions)), 1  # All boxes in storage: terminal state\n",
        "    else:\n",
        "        return (new_agent_pos, tuple(new_box_positions)), 0  # Valid move, continue\n",
        "\n",
        "def is_terminal(state, storage_pos):\n",
        "    _, box_positions = state\n",
        "    return all(box in storage_pos for box in box_positions)\n",
        "\n",
        "# Call Every-Visit Monte Carlo Control\n",
        "every_visit_mc(grid, initial_agent_pos, initial_box_pos, storage_pos)"
      ],
      "metadata": {
        "id": "0XHGyxu5ynCw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}