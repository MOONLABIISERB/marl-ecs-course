{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best time (minimum time taken to solve): 0.0050051212 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import random\n",
    "import time  # Import the time module\n",
    "from collections import defaultdict\n",
    "\n",
    "# Grid and environment\n",
    "grid = [\n",
    "    \"_,_,_,_,#,_,_,_,_,_\",\n",
    "    \"_,s1,_,_,#,g2,_,_,s3,_\",\n",
    "    \"_,_,_,_,#\",\"#,_,_,_,_\",\n",
    "    \"_,_,_,_,_,_,_,_,_,_\",\n",
    "    \"#\",\"#\",\"#,_,_,_,_,#\",\"#\",\"#\",\n",
    "    \"_,g4\",\"#,_,_,_,_,#,g1,_\",\n",
    "    \"_,_,_,_,_,_,_,_,_,_\",\n",
    "    \"_,_,_,_,#\",\"#,_,_,_,_\",\n",
    "    \"_,s2,_,_,g3\",\"#,_,_,s4,_\",\n",
    "    \"_,_,_,_,_,#,\"\",\"#\"\n",
    "]\n",
    "\n",
    "# Map positions\n",
    "START_POS = [(1, 1), (8, 1), (1, 8), (8, 8)]\n",
    "GOALS = [(5, 8), (1, 5), (8, 4), (5, 1)]\n",
    "OBSTACLES = [(r, c) for r, row in enumerate(grid) for c, val in enumerate(row.split(\",\")) if val == \"#\"]\n",
    "\n",
    "# Parameters\n",
    "ACTIONS = [(0, 1), (0, -1), (1, 0), (-1, 0), (0, 0)]  # Right, Left, Down, Up, Stay\n",
    "epsilon = 0.1  # Exploration factor\n",
    "alpha = 0.1  # Learning rate\n",
    "gamma = 0.9  # Discount factor\n",
    "\n",
    "def is_valid(pos):\n",
    "    \"\"\"Check if the position is valid and not an obstacle.\"\"\"\n",
    "    return (\n",
    "        0 <= pos[0] < len(grid) and\n",
    "        0 <= pos[1] < len(grid[0].split(\",\")) and\n",
    "        pos not in OBSTACLES\n",
    "    )\n",
    "\n",
    "def q_learning_multi_agent(start_positions, goals, max_episodes=1000):\n",
    "    \"\"\"Multi-agent Q-learning for navigation.\"\"\"\n",
    "    q_tables = [defaultdict(float) for _ in range(len(start_positions))]\n",
    "    policy = [defaultdict(int) for _ in range(len(start_positions))]\n",
    "    \n",
    "    best_time = float('inf')  # Initialize best time to infinity to track the minimum\n",
    "\n",
    "    for episode in range(max_episodes):\n",
    "        start_time = time.time()  # start time of the episode\n",
    "        \n",
    "        positions = start_positions[:]\n",
    "        steps = 0\n",
    "        \n",
    "        # Run episode until all agents reach their goal\n",
    "        while any(pos != goal for pos, goal in zip(positions, goals)):\n",
    "            new_positions = positions[:]\n",
    "            for i, (pos, goal) in enumerate(zip(positions, goals)):\n",
    "                if pos == goal:\n",
    "                    continue\n",
    "\n",
    "                state = tuple(positions)\n",
    "\n",
    "                # Epsilon-greedy action selection\n",
    "                if random.random() < epsilon:\n",
    "                    action = random.choice(range(len(ACTIONS)))\n",
    "                else:\n",
    "                    action = max(\n",
    "                        range(len(ACTIONS)), \n",
    "                        key=lambda a: q_tables[i][(state, a)]\n",
    "                    )\n",
    "\n",
    "                # Action execution\n",
    "                move = ACTIONS[action]\n",
    "                next_pos = (pos[0] + move[0], pos[1] + move[1])\n",
    "                \n",
    "                # Collision and boundary handling\n",
    "                if not is_valid(next_pos) or next_pos in new_positions:\n",
    "                    next_pos = pos\n",
    "                new_positions[i] = next_pos\n",
    "\n",
    "                # Update Q-table\n",
    "                reward = -1 if next_pos != goal else 0\n",
    "                next_state = tuple(new_positions)\n",
    "                best_next_action = max(\n",
    "                    q_tables[i][(next_state, a)] for a in range(len(ACTIONS))\n",
    "                )\n",
    "                q_tables[i][(state, action)] += alpha * (\n",
    "                    reward + gamma * best_next_action - q_tables[i][(state, action)]\n",
    "                )\n",
    "\n",
    "                # Update policy\n",
    "                policy[i][state] = max(\n",
    "                    range(len(ACTIONS)), \n",
    "                    key=lambda a: q_tables[i][(state, a)]\n",
    "                )\n",
    "\n",
    "            positions = new_positions\n",
    "            steps += 1\n",
    "        \n",
    "        end_time = time.time()  # Record the end time of episode\n",
    "        episode_time = end_time - start_time  # Calculate the time taken for the episode\n",
    "        \n",
    "        # Track the best (minimum) time across episodes\n",
    "        if episode_time < best_time:\n",
    "            best_time = episode_time\n",
    "\n",
    "    return policy, best_time\n",
    "\n",
    "\n",
    "policy, best_time = q_learning_multi_agent(START_POS, GOALS)\n",
    "print(f\"Best time (minimum time taken to solve): {best_time:.10f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
