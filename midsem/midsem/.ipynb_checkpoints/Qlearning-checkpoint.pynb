{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abc3dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a14d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3459f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modified_tsp import ModTSP\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "def state_to_tuple(state):\n",
    "    return tuple(state.astype(int))\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, action_space = 10, learning_rate=0.1, discount_factor=0.99):\n",
    "        self.action_space = action_space \n",
    "        self.learning_rate = learning_rate \n",
    "        self.discount_factor = discount_factor  \n",
    "        self.q_table = {}  \n",
    "        self.td_errors = [] \n",
    "\n",
    "    def choose_action(self, state):\n",
    "        \"\"\"Choose the best action based on the current Q-values (greedy policy).\"\"\"\n",
    "        state_str = state_to_tuple(state)\n",
    "        if state_str not in self.q_table:\n",
    "            self.q_table[state_str] = np.zeros(self.action_space)  \n",
    "        return np.argmax(self.q_table[state_str])  \n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        \"\"\"Update the Q-value for the given state-action pair.\"\"\"\n",
    "        state_str = state_to_tuple(state)\n",
    "        next_state_str = state_to_tuple(next_state)\n",
    "\n",
    "        \n",
    "        if next_state_str not in self.q_table:\n",
    "            self.q_table[next_state_str] = np.zeros(self.action_space)\n",
    "\n",
    "\n",
    "        next_action = np.argmax(self.q_table[next_state_str]) \n",
    "        td_target = reward + self.discount_factor * self.q_table[next_state_str][next_action]\n",
    "        td_error = td_target - self.q_table[state_str][action]\n",
    "\n",
    "        self.td_errors.append(abs(td_error))\n",
    "\n",
    "        \n",
    "        self.q_table[state_str][action] += self.learning_rate * td_error\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Main function to run Q-learning agent in Modified TSP environment.\"\"\"\n",
    "\n",
    "    num_episodes = 9999\n",
    "\n",
    "    env = ModTSP()\n",
    "    agent = QLearningAgent()\n",
    "    \n",
    "    \n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_dir = f'logs/{current_time}'\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    pbar = tqdm(range(num_episodes), desc=\"Training Progress\")\n",
    "    for ep in pbar:\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.choose_action(state)\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action) \n",
    "            done = terminated or truncated\n",
    "\n",
    "            agent.update_q_value(state, action, reward, next_state) \n",
    "\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "        writer.add_scalar('Reward/Episode', total_reward, ep)\n",
    "        writer.add_scalar('Loss/Episode', np.mean(agent.td_errors), ep)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca18fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b3bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
